{"server": "epsilon", "data_name": "davidson-2017", "data_split": "dev", "data_size": 298, "label2index": {"hatespeech": 0, "offensive": 1, "normal": 2}, "label_col": "label_multi", "dataset_type": "multi", "label_counts": {"1": 231, "2": 50, "0": 17}, "llm_name": "flan-t5-xl", "task_name": "text2text-generation", "batch_size": 32, "top_p": 1.0, "temperature": 0.0, "repetition_penalty": 1, "do_sample": false, "top_k": 50, "typical_p": 1.0, "num_return_sequences": 1, "seed_generation": 42, "prompt_type": "vanilla-nho-occurrence-321-temp0.0-seed42", "prompt_template": "Consider that the text originates from a dataset where offensive occurs more frequently than hatespeech, normal occurs more frequently than hatespeech, and offensive occurs more frequently than normal.\nBased on this classify the text delimited by three backticks as normal, hatespeech, or offensive. Provide the answer as either normal, hatespeech, or offensive only.\nExample output for normal : normal\nExample output for hatespeech : hatespeech\nExample output for offensive : offensive\n``` {text}```", "text_placeholder": "{text}", "predictions_filename": "outputs/davidson-2017/dev/davidson-2017_dev_multi_flan-t5-xl_vanilla-nho-occurrence-321-temp0.0-seed42_predictions_raw.json", "success_rate": 1.0, "f1score": 0.7292199903946663, "f1score_label": {"hatespeech": 0.48148148148148157, "offensive": 0.9061784897025171, "normal": 0.8000000000000002}, "confusion_matrix_filename": "outputs/davidson-2017/dev/davidson-2017_dev_multi_flan-t5-xl_vanilla-nho-occurrence-321-temp0.0-seed42_confusion_matrix.png", "pred_imb_rate": {"hatespeech": 2.176470588235294, "offensive": 0.8917748917748918, "normal": 1.1}, "imb_rate_avg": 1.4659432705120885, "execution_time": 1811.7279951572418}