{"server": "epsilon", "data_name": "davidson-2017", "data_split": "dev", "data_size": 298, "label2index": {"hatespeech": 0, "offensive": 1, "normal": 2}, "label_col": "label_multi", "dataset_type": "multi", "label_counts": {"1": 231, "2": 50, "0": 17}, "llm_name": "flan-t5-xl", "task_name": "text2text-generation", "batch_size": 32, "top_p": 1.0, "temperature": 0.0, "repetition_penalty": 1, "do_sample": false, "top_k": 50, "typical_p": 1.0, "num_return_sequences": 1, "seed_generation": 42, "prompt_type": "vanilla-nho-occurrence-132-temp0.0-seed42", "prompt_template": "Consider that the text originates from a dataset where offensive occurs more frequently than normal, offensive occurs more frequently than hatespeech, and normal occurs more frequently than hatespeech.\nBased on this classify the text delimited by three backticks as normal, hatespeech, or offensive. Provide the answer as either normal, hatespeech, or offensive only.\nExample output for normal : normal\nExample output for hatespeech : hatespeech\nExample output for offensive : offensive\n``` {text}```", "text_placeholder": "{text}", "predictions_filename": "outputs/davidson-2017/dev/davidson-2017_dev_multi_flan-t5-xl_vanilla-nho-occurrence-132-temp0.0-seed42_predictions_raw.json", "success_rate": 1.0, "f1score": 0.7120692108483452, "f1score_label": {"hatespeech": 0.4307692307692308, "offensive": 0.8941176470588236, "normal": 0.8113207547169812}, "confusion_matrix_filename": "outputs/davidson-2017/dev/davidson-2017_dev_multi_flan-t5-xl_vanilla-nho-occurrence-132-temp0.0-seed42_confusion_matrix.png", "pred_imb_rate": {"hatespeech": 2.823529411764706, "offensive": 0.8398268398268398, "normal": 1.12}, "imb_rate_avg": 1.711417020416414, "execution_time": 722.0773255825043}