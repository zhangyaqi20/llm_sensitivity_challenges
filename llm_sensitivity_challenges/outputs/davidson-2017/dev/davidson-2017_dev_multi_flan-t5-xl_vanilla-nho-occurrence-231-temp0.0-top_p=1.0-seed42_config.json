{"server": "epsilon", "data_name": "davidson-2017", "data_split": "dev", "data_size": 298, "label2index": {"hatespeech": 0, "offensive": 1, "normal": 2}, "label_col": "label_multi", "dataset_type": "multi", "label_counts": {"1": 231, "2": 50, "0": 17}, "llm_name": "flan-t5-xl", "task_name": "text2text-generation", "batch_size": 32, "top_p": 1.0, "temperature": 0.0, "repetition_penalty": 1, "do_sample": false, "top_k": 50, "typical_p": 1.0, "num_return_sequences": 1, "seed_generation": 42, "prompt_type": "vanilla-nho-occurrence-231-temp0.0-seed42", "prompt_template": "Consider that the text originates from a dataset where normal occurs more frequently than hatespeech, offensive occurs more frequently than hatespeech, and offensive occurs more frequently than normal.\nBased on this classify the text delimited by three backticks as normal, hatespeech, or offensive. Provide the answer as either normal, hatespeech, or offensive only.\nExample output for normal : normal\nExample output for hatespeech : hatespeech\nExample output for offensive : offensive\n``` {text}```", "text_placeholder": "{text}", "predictions_filename": "outputs/davidson-2017/dev/davidson-2017_dev_multi_flan-t5-xl_vanilla-nho-occurrence-231-temp0.0-seed42_predictions_raw.json", "success_rate": 1.0, "f1score": 0.7540318806287125, "f1score_label": {"hatespeech": 0.5405405405405405, "offensive": 0.9254385964912282, "normal": 0.796116504854369}, "confusion_matrix_filename": "outputs/davidson-2017/dev/davidson-2017_dev_multi_flan-t5-xl_vanilla-nho-occurrence-231-temp0.0-seed42_confusion_matrix.png", "pred_imb_rate": {"hatespeech": 1.1764705882352942, "offensive": 0.974025974025974, "normal": 1.06}, "imb_rate_avg": 1.0877124183006537, "execution_time": 1447.9231610298157}