{"server": "epsilon", "data_name": "davidson-2017", "data_split": "test", "data_size": 4957, "label2index": {"hatespeech": 0, "offensive": 1, "normal": 2}, "label_col": "label_multi", "dataset_type": "multi", "label_counts": {"1": 3838, "2": 833, "0": 286}, "llm_name": "flan-t5-xl", "task_name": "text2text-generation", "batch_size": 32, "top_p": 0.7, "seed_generation": 21, "top_k": 50, "typical_p": 1.0, "num_return_sequences": 1, "temperature": 0.7, "repetition_penalty": 1, "do_sample": true, "prompt_type": "vanilla-nho-occurrence-same-temp0.7-top_p=0.7-seed21", "prompt_template": "Consider that the text originates from a dataset where normal, hatespeech, and offensive occur with the same frequency.\nBased on this classify the text delimited by three backticks as normal, hatespeech, or offensive. Provide the answer as either normal, hatespeech, or offensive only.\nExample output for normal : normal\nExample output for hatespeech : hatespeech\nExample output for offensive : offensive\n``` {text}```", "text_placeholder": "{text}", "predictions_filename": "outputs/davidson-2017/test/davidson-2017_test_multi_flan-t5-xl_vanilla-nho-occurrence-same-temp0.7-top_p=0.7-seed21_predictions.json", "success_rate": 1.0, "recall": 0.7378008229642266, "recall_label": {"hatespeech": 0.40559440559440557, "offensive": 0.9098488796248045, "normal": 0.8979591836734694}, "|Rec - Rec_i|_avg": 0.22147094491321392, "f1score": 0.717009518292577, "f1score_label": {"hatespeech": 0.3580246913580247, "offensive": 0.9262599469496021, "normal": 0.8667439165701043}, "acc_score": 0.8787573128908615, "confusion_matrix_filename": "outputs/davidson-2017/test/davidson-2017_test_multi_flan-t5-xl_vanilla-nho-occurrence-same-temp0.7-top_p=0.7-seed21_confusionmatrix.png", "TP": [116, 3492, 748], "TN": [4425, 909, 3979], "FP": [246, 210, 145], "FN": [170, 346, 85], "FPR": {"hatespeech": 0.05266538214515093, "offensive": 0.1876675603217158, "normal": 0.03516003879728419}, "FPR_overall": 0.09183099375471697, "|FPR - FPR_i|_avg": 0.06389104437799921, "FNR": {"hatespeech": 0.5944055944055944, "offensive": 0.09015112037519542, "normal": 0.10204081632653061}, "FNR_overall": 0.2621991770357735, "|FNR - FNR_i|_avg": 0.22147094491321395, "FPR - FNR": {"hatespeech": -0.5417402122604434, "offensive": 0.09751643994652039, "normal": -0.06688077752924643}, "|FPR - FNR|_avg": 0.2353791432454034, "pred_imb_rate": {"hatespeech": 0.26573426573426573, "offensive": -0.03543512245961438, "normal": 0.07202881152460984}, "imb_rate_avg": 0.12439939990616332, "execution_time": 30.63521409034729}