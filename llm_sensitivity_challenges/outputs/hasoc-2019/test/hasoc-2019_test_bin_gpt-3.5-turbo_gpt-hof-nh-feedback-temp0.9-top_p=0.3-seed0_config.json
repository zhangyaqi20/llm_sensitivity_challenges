{"server": "epsilon", "data_name": "hasoc-2019", "data_split": "test", "data_size": 1153, "label2index": {"no": 0, "yes": 1}, "label_col": "label", "dataset_type": "bin", "label_counts": {"0": 865, "1": 288}, "llm_name": "gpt-3.5-turbo", "task_name": "chat-completion", "batch_size": 32, "top_p": 0.3, "seed_generation": 0, "temperature": 0.9, "frequency_penalty": 0, "presence_penalty": 0, "stop": [",", ".", "\n"], "max_new_tokens": 20, "prompt_type": "gpt-hof-nh-feedback-temp0.9-top_p=0.3-seed0", "prompt_template": "Text: ``` {text}```\nYou predicted almost as much hatespeech or offensive as what is actually present in the dataset.\nIs this text hatespeech or offensive? Answer in one word with NO or YES only.", "text_placeholder": "{text}", "predictions_filename": "outputs/hasoc-2019/test/hasoc-2019_test_bin_gpt-3.5-turbo_gpt-hof-nh-feedback-temp0.9-top_p=0.3-seed0_predictions.json", "success_rate": 1.0, "recall": 0.7570066634553629, "recall_label": {"no": 0.892485549132948, "yes": 0.6215277777777778}, "|Rec - Rec_i|_avg": 0.1354788856775851, "f1score": 0.7617963508427426, "f1score_label": {"no": 0.884306987399771, "yes": 0.6392857142857142}, "acc_score": 0.8248048568950563, "confusion_matrix_filename": "outputs/hasoc-2019/test/hasoc-2019_test_bin_gpt-3.5-turbo_gpt-hof-nh-feedback-temp0.9-top_p=0.3-seed0_confusionmatrix.png", "TP": [772, 179], "TN": [179, 772], "FP": [109, 93], "FN": [93, 109], "FPR": {"no": 0.3784722222222222, "yes": 0.10751445086705202}, "FPR_overall": 0.24299333654463712, "|FPR - FPR_i|_avg": 0.1354788856775851, "FNR": {"no": 0.10751445086705202, "yes": 0.3784722222222222}, "FNR_overall": 0.24299333654463712, "|FNR - FNR_i|_avg": 0.1354788856775851, "FPR - FNR": {"no": 0.2709577713551702, "yes": -0.2709577713551702}, "|FPR - FNR|_avg": 0.2709577713551702, "pred_imb_rate": {"no": 0.018497109826589597, "yes": -0.05555555555555555}, "imb_rate_avg": 0.037026332691072576, "execution_time": 506.57233023643494}