{"server": "epsilon", "data_name": "civil-comments", "data_split": "test", "data_size": 5000, "label2index": {"no": 0, "yes": 1}, "label_col": "label", "dataset_type": "bin", "label_counts": {"0": 4601, "1": 399}, "llm_name": "gpt-3.5-turbo", "task_name": "chat-completion", "batch_size": 32, "top_p": 0.3, "seed_generation": 21, "temperature": 0.9, "frequency_penalty": 0, "presence_penalty": 0, "stop": [",", ".", "\n"], "max_new_tokens": 20, "prompt_type": "gpt-toxic-hn-feedback-temp0.9-top_p=0.3-seed21", "prompt_template": "Text: ``` {text}```\nYou predicted almost twice as much toxic as what is actually present in the dataset.\nIs this text toxic? Answer in one word with YES or NO only.", "text_placeholder": "{text}", "predictions_filename": "outputs/civil-comments/test/civil-comments_test_bin_gpt-3.5-turbo_gpt-toxic-hn-feedback-temp0.9-top_p=0.3-seed21_predictions.json", "success_rate": 1.0, "recall": 0.6353691226544954, "recall_label": {"no": 0.9374049119756575, "yes": 0.3333333333333333}, "|Rec - Rec_i|_avg": 0.30203578932116204, "f1score": 0.6320208300122218, "f1score_label": {"no": 0.9396514161220044, "yes": 0.32439024390243903}, "acc_score": 0.8892, "confusion_matrix_filename": "outputs/civil-comments/test/civil-comments_test_bin_gpt-3.5-turbo_gpt-toxic-hn-feedback-temp0.9-top_p=0.3-seed21_confusionmatrix.png", "TP": [4313, 133], "TN": [133, 4313], "FP": [266, 288], "FN": [288, 266], "FPR": {"no": 0.6666666666666666, "yes": 0.06259508802434254}, "FPR_overall": 0.3646308773455046, "|FPR - FPR_i|_avg": 0.30203578932116204, "FNR": {"no": 0.06259508802434254, "yes": 0.6666666666666666}, "FNR_overall": 0.3646308773455046, "|FNR - FNR_i|_avg": 0.30203578932116204, "FPR - FNR": {"no": 0.6040715786423241, "yes": -0.6040715786423241}, "|FPR - FNR|_avg": 0.6040715786423241, "pred_imb_rate": {"no": -0.004781569224081721, "yes": 0.05513784461152882}, "imb_rate_avg": 0.029959706917805272, "execution_time": 4888.918367862701}