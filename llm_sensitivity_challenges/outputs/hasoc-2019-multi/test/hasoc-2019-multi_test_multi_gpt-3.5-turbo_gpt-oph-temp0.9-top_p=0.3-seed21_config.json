{"server": "epsilon", "data_name": "hasoc-2019-multi", "data_split": "test", "data_size": 288, "label2index": {"hatespeech": 0, "profane": 1, "offensive": 2}, "label_col": "label_multi", "dataset_type": "multi", "label_counts": {"0": 124, "1": 93, "2": 71}, "llm_name": "gpt-3.5-turbo", "task_name": "chat-completion", "batch_size": 32, "top_p": 0.3, "seed_generation": 21, "temperature": 0.9, "frequency_penalty": 0, "presence_penalty": 0, "stop": [",", ".", "\n"], "max_new_tokens": 20, "prompt_type": "gpt-oph-temp0.9-top_p=0.3-seed21", "prompt_template": "Text: ``` {text}```\nIs this text OFFENSIVE, PROFANE, or HATESPEECH? Answer in one word with OFFENSIVE, PROFANE, or HATESPEECH only.", "text_placeholder": "{text}", "predictions_filename": "outputs/hasoc-2019-multi/test/hasoc-2019-multi_test_multi_gpt-3.5-turbo_gpt-oph-temp0.9-top_p=0.3-seed21_predictions.json", "success_rate": 0.9756944444444444, "recall": 0.5371102259019154, "recall_label": {"hatespeech": 0.288135593220339, "profane": 0.4946236559139785, "offensive": 0.8285714285714286}, "|Rec - Rec_i|_avg": 0.19430746844634217, "f1score": 0.5020909024199559, "f1score_label": {"hatespeech": 0.4096385542168675, "profane": 0.6344827586206896, "offensive": 0.4621513944223108}, "acc_score": 0.49110320284697506, "confusion_matrix_filename": "outputs/hasoc-2019-multi/test/hasoc-2019-multi_test_multi_gpt-3.5-turbo_gpt-oph-temp0.9-top_p=0.3-seed21_confusionmatrix.png", "TP": [34, 46, 58], "TN": [149, 182, 88], "FP": [14, 6, 123], "FN": [84, 47, 12], "FPR": {"hatespeech": 0.08588957055214724, "profane": 0.031914893617021274, "offensive": 0.5829383886255924}, "FPR_overall": 0.233580950931587, "|FPR - FPR_i|_avg": 0.23290495846267031, "FNR": {"hatespeech": 0.711864406779661, "profane": 0.5053763440860215, "offensive": 0.17142857142857143}, "FNR_overall": 0.4628897740980846, "|FNR - FNR_i|_avg": 0.19430746844634217, "FPR - FNR": {"hatespeech": -0.6259748362275137, "profane": -0.47346145046900023, "offensive": 0.411509817197021}, "|FPR - FNR|_avg": 0.503648701297845, "pred_imb_rate": {"hatespeech": -0.5932203389830508, "profane": -0.44086021505376344, "offensive": 1.5857142857142856}, "imb_rate_avg": 0.8732649465837, "execution_time": 111.09093189239502}